# Assignment 2
In this assignment, we will use what we've learned about modeling for marketing applications. This is structured as a competition where you and your team tries to do the best job of predicting household behavior.

## Insurance for Chinese farmers
This uses data from a study of the sale of farmers insurance to rural Chinese farmers. You can get the data [here](https://www.dropbox.com/s/uvej3ry3j84ms24/insurance_prediction_training.csv?dl=0).

You will attempt to predict the purchase (`takeup`) of this insurance product. We suggest starting with penalized regression.

```{r, message=FALSE, results='hide'}
library(glmnet)
library(dplyr)
library(Hmisc)
library(lubridate)
library(ggplot2)
library(readr)
theme_set(theme_bw())
```

## Load and examine data
Load the data file. You may also want to do some exploratory data analysis to better understand this data set.

```{r}
data <- readr::read_csv("insurance_prediction_training.csv")

# Preprocessing

data$educ <- ifelse(is.na(data$educ), 0, data$educ)

data$rice_inc <- data$rice_inc / 100
data$educ <- data$educ / 4
data$disaster_loss <- data$disaster_loss / 100

```

Some info about the variables:
- `region` code for region of household and farm
- `takeup` whether they bought farmers insurance for this season -- our outcome
- `age` of head of household
- `agpop` is the number of people in the household
- `rice_inc` is a measure of income from selling rice last year
- `ricearea_2010` the size of the rice cultivation area 
- `disaster_loss` is the loss in cultivation area from a disaster last year
- `disaster_yes` is just an indicator for whether they were affected by a disaster last year

## Modeling

### FGPT GPT GPT
0.669

```{r}
data.nonmissing <- data[c("id","region","village","age","agpop","rice_inc","ricearea_2010","general_trust","educ","educ_good","male","disaster_loss","disaster_yes","risk_averse","literacy", "takeup")]

data.nonmissing <- na.omit(data.nonmissing)

data.nonmissing$region <- as.factor(data.nonmissing$region)
data.nonmissing$village <- as.factor(data.nonmissing$village)

# drop village
data.nonmissing <- subset(data.nonmissing, select = -c(village))

data_takeup_copy <- data.nonmissing$takeup

data.nonmissing$takeup <- ifelse(data.nonmissing$takeup == 0, "no", "yes")

data.nonmissing$takeup <- as.factor(data.nonmissing$takeup)

data.nonmissing
```

#### Fix the region and village columns

```{r}
encoded_region <- model.matrix(~region - 1, data = data.nonmissing)
encoded_region_df <- as.data.frame(encoded_region)
data.nonmissing <- cbind(data.nonmissing, encoded_region_df)
data.nonmissing <- subset(data.nonmissing, select = -c(region))

# encoded_village <- model.matrix(~village - 1, data = data.nonmissing)
# encoded_village_df <- as.data.frame(encoded_village)
# data.nonmissing <- cbind(data.nonmissing, encoded_village_df)
# data.nonmissing <- subset(data.nonmissing, select = -c(village))

data.nonmissing
```


```{r}
# Load necessary libraries
library(caret)
library(glmnet)
library(Metrics)

# Load your dataset

# Convert 'takeup' column to factor if it's not already
data.nonmissing$takeup <- as.factor(data.nonmissing$takeup)

# Define the control parameters for cross-validation
ctrl <- trainControl(method = "cv",   # Cross-validation method
                     number = 5, 
                     savePredictions = TRUE, # Number of folds
                     summaryFunction = mnLogLoss,  # Summary function for logLoss
                     classProbs = TRUE)  # Needed for logLoss calculation

# Create a matrix of predictors
predictors <- as.matrix(data.nonmissing[, c(-which(names(data.nonmissing) == "takeup"),-which(names(data.nonmissing) == "id"))])

# Create a grid of lambda values
lambda <- 10^seq(-4, 4, length.out = 100)

# Define the model to tune
model <- train(x = predictors,             # Predictor matrix
               y = data.nonmissing$takeup,       # Response variable
               method = "glmnet",          # Use glmnet for LASSO logistic regression
               trControl = ctrl,           # Cross-validation control parameters
               tuneGrid = expand.grid(alpha = 1, lambda = lambda),  # Grid of alpha and lambda values
               preProcess = c("center", "scale"),  # Preprocessing steps
               metric = "logLoss",         # Evaluation metric
               tuneLength = 100)           # Number of lambda values to try

# Print the best model's hyperparameters
print(model) 

# Plot the performance of different hyperparameter combinations
plot(model)

```

```{r}
predictors
```


```{r}
# Extract coefficients from the best model
coefficients <- coef(model$finalModel, s = model$bestTune$lambda)
model$results
coefficients

```

# Calibrations

```{r}
# Make predictions on the training set to use for calibration
train_probabilities <- predict(model, newdata = predictors, type = "prob")

# Fit a calibration model on top of the LASSO model using Platt scaling
calibration_model <- glm(takeup ~ 1 + prob, data = data.frame(takeup = data.nonmissing$takeup, prob = train_probabilities[, "yes"]), family = binomial(link = "logit"))

train_probabilities_calibrated <- predict(calibration_model, newdata = data.frame(prob = train_probabilities[, "yes"]), type = "response")
```

```{r}
# train_probabilities[, "yes"]
library(Metrics)
print(logLoss(data_takeup_copy, train_probabilities[, "yes"]))
print(logLoss(data_takeup_copy, train_probabilities_calibrated))
```

```{r}
# model$finalModel
train_probabilities
```


#### Test dataset

```{r}
data.test <- readr::read_csv("insurance_prediction_to_predict.csv")

data.test <- data.test[c("id","region","village","age","agpop","rice_inc","ricearea_2010","general_trust","educ","educ_good","male","disaster_loss","disaster_yes","risk_averse","literacy")]

data.test$region <- as.factor(data.test$region)
data.test$village <- as.factor(data.test$village)

# drop village
data.test <- subset(data.test, select = -c(village))


# Replace NA in Educ with 0 
data.test$educ <- ifelse(is.na(data.test$educ), 0, data.test$educ)

# Scale the variables and rescale educ
data.test$rice_inc <- data.test$rice_inc / 100
data.test$educ <- data.test$educ / 4
data.test$disaster_loss <- data.test$disaster_loss / 100


#####

encoded_region <- model.matrix(~region - 1, data = data.test)
encoded_region_df <- as.data.frame(encoded_region)
data.test <- cbind(data.test, encoded_region_df)
data.test <- subset(data.test, select = -c(region))

# encoded_village <- model.matrix(~village - 1, data = data.test)
# encoded_village_df <- as.data.frame(encoded_village)
# data.test <- cbind(data.test, encoded_village_df)
# data.test <- subset(data.test, select = -c(village))

#####

test_predictors <- as.matrix(data.test[, -which(names(data.test) == "id")])

# Make predictions on the test set
test_probabilities <- predict(model, newdata = test_predictors, type = "prob")

# Calibrate the predicted probabilities using the calibration model
calibrated_probabilities <- predict(calibration_model, newdata = data.frame(prob = test_probabilities[, "yes"]), type = "response")

# Print the calibrated predicted probabilities

data.test$takeup.hat <- test_probabilities[, "yes"]
data.test$takeup.hat.calibrated <- calibrated_probabilities

predictions <- data.test %>%
    select(id, takeup = takeup.hat.calibrated)

predictions

write.csv(predictions, "calibrated_predictions_824pm.csv", row.names = F)
```


```{r}
data.test
```


## Classwork stuff


You should fit a model predicting takeup using the methods we discussed in class and illustrated in the worked example for caravan insurance.

This includes:
- Fitting a model and using cross-validation to estimate prediction error.
- Examining the estimated prediction error as a function of the penalty
- Extracting and examining predictions from the model


```{r}
formula.val <-  ~ -1 + factor(region) + rice_inc + literacy + educ_good # + risk_averse + disaster_yes + ricearea_2010

mm.val <- sparse.model.matrix(formula.val, data = data)
```

```{r}
set.seed(3100)
glmnet.1val <- cv.glmnet(
    mm.val, data$takeup,
    family = "binomial",
    alpha = 0,
    nfolds = 10
    )
```

```{r}
plot(glmnet.1val)
opt_lambda = glmnet.1val$lambda.min
se1_lambda = glmnet.1val$lambda.1se
opt_lambda
```

```{r}
val.hat = predict(
  glmnet.1val, newx = mm.val,
  type = "response", s = glmnet.1val$lambda.min,
)[,1]
print(summary(val.hat))
```

```{r}
# install.packages('Metrics')
library(Metrics)
logLoss(data$takeup, val.hat)
```


## Now working with the full training set for pre-submission

A very basic model formula would be something like the one below, but you probably want to consider higher-dimensional models:

```{r}
formula.1 <-  ~ -1 + factor(region) + rice_inc + literacy + risk_averse + disaster_yes

mm.1 <- sparse.model.matrix(formula.1, data = data)
```

```{r}
set.seed(3100)
glmnet.1 <- glmnet(
    mm.1, data$takeup,
    family = "binomial",
    alpha = 0,
    lambda = opt_lambda
    )
```

## Suggested questions to ask yourselves
What predictors of insurance purchase do you find? Think of interpretations for some. You might want to try using some lasso (L1) penalty to set many coefficients to exactly zero. You can do this with `cv.glmnet` by setting `alpha > 0`.

What penalty (lambda) did you select? How?

You may want to refer to the lab.

## Submitting predictions
Now get predictions for new households where we don't know yet whether they will buy insurance. You can get the data [here](https://www.dropbox.com/s/kjer33epe4ht042/insurance_prediction_to_predict.csv?dl=0).

```{r}
data.test <- readr::read_csv("insurance_prediction_to_predict.csv")

data.test$rice_inc <- data.test$rice_inc / 100
data.test$educ <- data.test$educ / 4
data.test$disaster_loss <- data.test$disaster_loss / 100
```

You should have 9805 households in the test data. (If not, download this file again, as the link above briefly pointed to the wrong file.)
```{r}
nrow(data.test)
```


Getting predictions will look something like this, assuming you have a formula object created earlier named `formula.1`:

```{r}
mm.test <- sparse.model.matrix(
    formula.1,
    data = data.test,
    drop.levels = FALSE
    )
mm.test <- mm.test[, colnames(mm.1)]

data.test$takeup.hat <- predict(
    glmnet.1,
    s = opt_lambda, # lambda
    newx = mm.test,
    type = "response"
)[, 1]
```



```{r}
data.test %>% select(id, region, rice_inc, takeup.hat) %>% head()
```

These (the entries in `takeup.hat`) are our predictions for these new households. You can now write these to a file and upload to [Kaggle](https://www.kaggle.com/c/mitsloanprediction2020).

```{r}
predictions <- data.test %>%
    select(id, takeup = takeup.hat)

write.csv(predictions, "our_predictions3.csv", row.names = F)
```

Your predictions will be scored against the whether these households actually purchase. (In particular, we use what is alternatively called "logistic loss", "log loss", or "binomial deviance". What is most important is that if they purchase, higher probabilities score better; if they don't purchase, lower probabilities score better.)


